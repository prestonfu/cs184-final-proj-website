<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="Accelerated Ray Tracing and Enhanced Marching for Integrated flocking with point cloudS"
    />
    <meta "og:image" content="static/images/deer-family.png" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ARTEMIS, CS 184 Final Project</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"
    ></script> -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [
            ["$", "$"],
            ["\\(", "\\)"],
          ],
        },
      };
    </script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }

      gtag("js", new Date());

      gtag("config", "G-PYVRSFMDRL");
    </script>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|IBM+Plex+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.png" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>

  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false"
        >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>

      <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>
  </div> -->
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title dnerf">
                ARTEMIS: Accelerated Ray Tracing and Enhanced Marching for
                Integrated flocking with point cloudS
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <p>Ralph Cao</p>
                </span>
                <span class="author-block">
                  <p>3037721429</p>
                </span>
                <span class="author-block">
                  <p>ralph_cow@berkeley.edu</p>
                </span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <p>Arjun Damerla</p>
                </span>
                <span class="author-block">
                  <p>3036679871</p>
                </span>
                <span class="author-block">
                  <p>arjundamerla@berkeley.edu</p>
                </span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <p>Preston Fu</p>
                </span>
                <span class="author-block">
                  <p>3036364629</p>
                </span>
                <span class="author-block">
                  <p>prestonfu@berkeley.edu</p>
                </span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <p>Julia Sun</p>
                </span>
                <span class="author-block">
                  <p>3037171474</p>
                </span>
                <span class="author-block">
                  <p>jsun28@berkeley.edu</p>
                </span>
              </div>
              <br />
              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  >CS 184, Computer Graphics and Imaging</span
                >
              </div>

              <br />

              <!-- <div align="middle">
                <h2>
                  <a
                    href="https://docs.google.com/presentation/d/120M-5wzmt5IsNDmXZB47CACTrW2VtXqy05xqt6myKto/edit?usp=sharing"
                    >Slides Link</a
                  >
                </h2>
                <h2>
                  <a
                    href="https://drive.google.com/file/d/1ae08E61iPUZnDG8u-HIQmOJFnWpnZAq8/view"
                    >Video Link</a
                  >
                </h2>
              </div> -->

              <!-- 
          <div class="column has-text-centered">
            <div class="publication-links">
            
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <span class="link-block">
                <a
                  href="https://github.com/prestonfu/cs184-final-proj"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark"
                >
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a
                  href="https://docs.google.com/presentation/d/120M-5wzmt5IsNDmXZB47CACTrW2VtXqy05xqt6myKto/edit?usp=sharing"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark"
                >
                  <span class="icon">
                    <i class="fab fa-slideshare"></i>
                  </span>
                  <span>Slides</span>
                </a>
              </span>
              <span class="link-block">
                <a
                  href="https://drive.google.com/file/d/14B83N3_aPqhC_QJxCm8ODTxdIcQcGiA0/view"
                  target="_blank"
                  class="external-link button is-normal is-rounded is-dark"
                >
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Showcase video</span>
                </a>
              </span>
              <!--
              <span class="link-block">https://prod.liveshare.vsengsaas.visualstudio.com/join?0A7051F5421BD8A68F474F037741D314857F
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>
            <!-- </div> -->
          </div>
        </div>
      </div>
    </section>

    <!--
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>
-->

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <div align="center">
              <video width="720" height="640" controls>
                <source src="static/videos/demo.mp4" type="video/mp4" />
              </video>
              <!-- <img
                src="static/gifs/demo.gif"
                align="middle"
                width="720px"
                height="640px"
              /> -->
            </div>
          </div>
        </div>
      </div>

      <br />
      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In this project, we provide an interactive flocking particle
                simulation which forms into point clouds generated by a
                text-to-3D model and implements GPU-accelerated ray marching and
                ray tracing for rendering. Our project was built from scratch
                from a barebones OpenCL sample.
              </p>
              <p>
                There are two versions of the project with different focuses.
                One has the full 4096 boids with very basic ray tracing and is
                optimized for frame rate, while the other has only 512 boids and
                implements ray marching with smoothing as well as ray tracing
                with light blocking and soft shadows.
              </p>

              <p>
                Our ray tracing and smoothed ray marching algorithm support
                large point clouds and interactive camera movements.
                Furthermore, we implemented a pipeline using pre-trained machine
                learning models to generate 3D point clouds from text. In order
                to accelerate our rendering, we utilized a wide array of
                optimization techniques, including using GPU acceleration from
                the OpenCL framework, BVH trees, and Morton codes for Z-order
                space-filling curves. We also implemented a boid flocking
                algorithm with a force toward our pre-generated point clouds,
                which smoothly interpolates boid positions and colors. With 4096
                boids, we achieve 60 FPS, compared to several seconds per frame
                without acceleration.
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Point Clouds</h2>
            <div class="content has-text-justified">
              <div align="middle">
                <img
                  src="static/images/pointcloudpipeline.png"
                  align="middle"
                  width="1000px"
                />
              </div>
              <br />
              <p>
                Our approach is shown in the figure above. To collect point
                clouds, we:
              </p>
              <ol>
                <li>
                  Generate text prompts with an LLM. We ran two prompts through
                  Claude 3 independently to generate lists of prompts: one for
                  real-life objects and well known characters for which I’d be
                  able to find images on Google, and one for easily recognizable
                  characters and objects performing whimsical actions.
                </li>
                <li>
                  For the first list, we scraped images off Google — partially
                  manually and partially with the
                  <a href="https://serpapi.com/" target="_blank">Serp API</a>.
                  For the second list, we ran prompts through
                  <a href="https://openai.com/dall-e-3" target="_blank"
                    >Dall-E 3</a
                  >. In each case, we specified that the image should have a
                  white background.
                </li>
                <li>
                  Preprocess the images, using a publicly available
                  <a
                    href="https://github.com/nadermx/backgroundremover"
                    target="_blank"
                    >background remover</a
                  >
                  to remove image backgrounds and resizing and centering images.
                </li>
                <li>
                  Input the resulting images to
                  <a href="https://openai.com/research/point-e" target="_blank"
                    >Point-E</a
                  >, which generates a 3D point cloud. We experimented with all
                  combinations of {preprocessed, not preprocessed} and {300M,
                  1B} model size, yielding a size-1024 point cloud $(x, y, z, r,
                  g, b)$. Then we ran a pre-trained upsampler to yield a
                  size-4096 point cloud of the same format. The model weights
                  are publicly available, and we ran the scripts on one V100
                  using Google Compute Engine. The total inference runtime for
                  654 images was around 6 hours. (Our original hope in this
                  project was that a user would enter text and have a point
                  cloud within seconds, but this inference procedure is the
                  bottleneck, in terms of time and cost.)

                  <br />
                  In general, we find that skipping the preprocessing step
                  consistently results in noise or artifacts in the edges and
                  corners of generated point clouds. We do not see a strong
                  change in model performance between 300M and 1B parameters for
                  contiguous objects, and that the common failure modes of
                  extraneous black pixels and geometrically flat outputs appear
                  consistently in both cases. For scenes containing multiple
                  disjoint objects, we found that the 1B model generally
                  performed better.
                </li>
              </ol>
              <p>
                The last step above resulted in point clouds with highly
                variable quality. We wrote a script to efficiently manually
                process these outputs. Out of around 150 randomly-sampled
                outputs, 40 were selected for use in our end product, and 
                16 are available to view in the application.
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Flocking</h2>
            <div class="content has-text-justified">
              <div align="middle">
                <img
                  src="static/images/flocking.png"
                  align="middle"
                  width="400px"
                />
              </div>
              <br />
              <p>
                Our flocking model incorporates the forces listed above. Each
                force has an associated radius, indicating that the force
                between two boids will only apply in the case that they are
                within some maximum $\ell_2$ distance. Each force also has a
                corresponding coefficient. These coefficients needed to be tuned
                quite carefully to achieve reasonable flocking behaviors: for
                instance, separation requires a specific value such that the
                boids do not suffer from mode collapse, and we introduced a weak
                “centering” force toward the origin to counteract the effect of
                “containing” trapping boids to the surface of a sphere. Our
                “arrival” force uses targets as the $(x,y,z)$ points generated
                in our point cloud procedure, which have been randomized by
                default to enable more cohesive transitions.
              </p>
              <p>
                We originally implemented our flocking algorithm in Unity. When
                we ported the code over to an OpenCL kernel, we found that the
                units were different, and every coefficient needed to be updated
                to work well with the rest of the codebase. We experienced some
                challenges with reading in the .npy outputs from Point-E in C++
                due to issues in the cnpy documentation, and ended up manually
                handling these issues after reading in the arrays.
              </p>
              <p>
                Our particle simulation is implemented using forward Euler. We
                found that it was sufficiently numerically stable and left a
                small memory footprint.
              </p>
              <p>
                Particle colors are updated by linear interpolation, with
                weights determined by the timestep. That is, $\mathbf c(t+1) =(1
                - \Delta t) \mathbf c(t) + \Delta t \mathbf
                c_{\text{target}}(t)$, where $\mathbf c = (r, g, b)$ denotes a
                particle's color as a function of time and $\mathbf
                c_{\text{target}}$ denotes the target color given by Point-E.
              </p>
              <div align="center">
                <video width="640" height="560" controls>
                  <source src="static/videos/flocking_4096.mov" />
                </video>
                <figcaption>Boid flocking with 4096 boids</figcaption>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Ray Marching</h2>
            <div class="content has-text-justified">
              <div align="middle">
                <table style="width: 100%">
                  <tr align="center">
                    <td>
                      <img
                        src="static/images/raymarching.png"
                        align="middle"
                        width="300px"
                      />
                      <figcaption></figcaption>
                    </td>
                  </tr>
                </table>
              </div>
              <p>
                Our ray marching algorithm was originally built on top of
                Homework 3 and tested in that codebase. We also enabled changing
                camera positions and continuous imaging renders. However, we
                found that the result was very laggy and rendered images slowly;
                simply streaming camera inputs is insufficient to render the
                whole scene smoothly in real time. Thus, we chose to accelerate
                this on the GPU using OpenCL, which we discuss in the following
                section.
              </p>

              <p>Below is a video of our original approach.</p>

              <div align="center">
                <video width="720" height="640" controls>
                  <source
                    src="static/videos/raymarchingvid.mp4"
                    type="video/mp4"
                  />
                </video>
              </div>

              <br />

              <p>
                We implemented smoothing with ray marching, such that two nearby spheres can
                merge and thus smooth out their collective surface. There are a
                <a href="https://iquilezles.org/articles/smin/" target="_blank"
                  >wide variety</a
                >
                of available smooth-min functions. We implemented the following
                approach: let $d_1$ denote the distance from the camera to the
                first sphere and $d_2$ to the second sphere. We also let $b =
                10^{-3}$ be a buffer constant. Then ray marching uses a distance
                defined by $$\min(d_1, d_2) - \frac b6 \left(\frac{\max(b - |d_1
                - d_2|, 0)}{b}\right)^3$$
              </p>

              <p>
                Computing normal vectors for smoothed surfaces relies on the
                signed distance field (SDF), which is defined by $f(\mathbf p) =
                \min_{\text{sphere}\ s = (\mathbf o, r)} \| \mathbf p - \mathbf
                o \| - r$ (that is, the distance to the nearest point on any
                sphere). Then we evaluate the gradient at $f(\mathbf p)$ with
                respect to each of the 6 positive and negative axis directions,
                and use these partial derivatives as components to compute the
                normal vector on the smoothed surface at $\mathbf p$.
              </p>
              <div align="middle">
                <table style="width: 100%">
                  <tr align="center">
                    <td>
                      <video width="640" height="560" controls>
                        <source src="static/videos/smooth_whale.mov" />
                      </video>
                      <figcaption>Blue Whale with smoothing, 512 boids</figcaption>
                    </td>
                    <td>
                      <video width="640" height="560" controls>
                        <source src="static/videos/flocking_smoothing.mov" />
                      </video>
                      <figcaption>Boid flocking with smoothing, 1024 boids</figcaption>
                    </td>
                  </tr>
                </table>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Ray Tracing</h2>
            <div class="content has-text-justified">
              <p>
                We implemented traditional ray tracing as well using OpenCL as
                a faster rendering option. We based our implementation off of
                Homework 3 and translated it to an OpenCL kernel with specifically
                the task of rendering multiple colored, diffuse spheres with a 
                single area light with multiple sample rays and multiple direct lighting
                samples. Due to OpenCL limitations and a lack of time, 
                we were only able to implement zero bounce and direct lighting 
                radiance. We were able to implement light blocking, however, leading 
                to some nice soft shadow effects. Unfortunately, in order to maintain
                a smooth frame rate, we do have a large amount of noise present in our 
                final renders.
              </p>

              <div align="center">
                <video width="640" height="560" controls>
                  <source src="static/videos/basketball_shadows.mov" />
                </video>
                <figcaption>Basketball with light blocking</figcaption>
              </div>
            </div>
          </div>
        </div>
      </div>


      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">OpenCL</h2>
            <div class="content has-text-justified">
              <p>
                Due to the low frame rate of CPU ray tracing, we decided to
                accelerate our rendering using OpenCL. Since Apple dropped 
                support for OpenGL, we were unable to use the built in OpenGL
                compute shaders for our ray tracing kernel. After surveying options
                such as Vulkan, Metal, and OpenCL, we ultimately decided on OpenCL
                due to its platform portability and its mix of ease of use and
                low level optimization capabilities. We used OpenCL in this project
                to parallelize the flocking algorithm and all three of our rendering
                implementations.
              </p>
              <p>
                Our flocking algorithm was split into two kernels, one for calculating
                accelerations based on the positions of other boids and one for integrating 
                the acceleration and updating position and velocity. These kernels 
                were executed once for each particle in the simulation on the GPU.
              </p>
              <p>
                In our ray tracing and ray marching kernels, we randomly generate rays 
                from each pixel of the camera and check for intersections with 
                each sphere in the scene. If we detect a collision, we then cast extra 
                rays from that collision point, randomly sampling from the area light
                in order to determine the radiance for that pixel. This is run in
                parallel on the GPU with one thread per pixel. For ray marching,
                we had to iterate our position based on the signed distance field
                to find intersections which significantly increased rendering time
                but allowed us to implement smoothing without having to modify meshes.
              </p>
              <p>
                We ran into a number of challenges when using OpenCL. None of us
                had any GPU experience on this level or any experience with
                OpenCL, so we had to learn the OpenCL environment from scratch,
                and had to navigate through GPU specific concepts such as work
                group thread synchronization through barrier calls, command
                queues, and GPU buffers.
              </p>
              <br />

              <h4>Deprecation</h4>

              <p>
                Apple dropped support for OpenCL in favor of their proprietary
                Metal API, leading to some incredibly difficult to trace bugs.
                After 4 hours of debugging on our first draft of the ray tracing
                compute shader, we realized that functions with pointer
                arguments had unpredictable behavior, and we were able to
                proceed with our implementation by limiting the use of helper
                functions.
              </p>
              <br />

              <h4>Speed</h4>

              <p>
                Despite reducing the number of operations by an order of
                magnitude, we still needed a number of optimizations in order to
                increase the frame rate to an acceptable amount for a stable
                simulation and comfortable user experience. These optimizations
                include utilizing local memory and work groups on the GPU,
                choosing an optimal work group size, and using an acceleration
                structure. These optimizations are benchmarked in the tables in
                the Results section.
              </p>
              <p>
                Our work group optimizations were generally based on finding a 
                spatial sorting of the points using a permutation index array 
                that grouped together points that were local and minimized the 
                bounding boxes for each. This is a very similar approach to a 
                standard BVH, however we chose to uniformly fix the size of each 
                leaf to match the work group size and only generate bounding boxes 
                for the leaves instead of traversing the BVH hierarchy from the root.
              </p>
              <p>
                Then, for the intersection check in our ray tracing kernel, each 
                thread would first intersect their ray with the bounding box of 
                the current BVH leaf. If all rays missed the bounding box, all 
                threads in the work group would skip to the next BVH leaf. In 
                this way, we can take advantage of the fact that rays from within 
                a work group have similar trajectories and avoid expensive 
                unnecessary accesses to global memory.
              </p>
              <p>
                We tested two different acceleration structures to generate the 
                BVH leaves used in our acceleration algorithm.
              </p>
              <ul>
                <li>
                  We implemented a low-depth BVH with axis splits along the
                  longest axis, with the motivation that we want our leaf nodes
                  to have uniform dimensions. Specifically, each split exactly
                  partitioned the points into two equally-sized groups, so that
                  we have an exactly balanced binary tree. The motivation is
                  that we have 16 work groups, each of size 256, so splitting
                  four times will exactly split boids into work groups.
                </li>
                <li>
                  We also implemented Morton codes for a Z-order space-filling
                  curve, following the description
                  <a
                    href="https://developer.nvidia.com/blog/thinking-parallel-part-iii-tree-construction-gpu/"
                    target="_blank"
                    >here</a
                  >. For a point $(x, y, z)$, we compute the binary
                  representations $x = 0.x_1 x_2 \dots$ (where $x_i \in \{0,
                  1\}$), and likewise for $y_i$ and $z_i$. Encoding the point as
                  $0.x_1 y_1 z_1 x_2 y_2 z_2 \dots$ results in a spatially-local
                  hash, i.e. points that have faraway encodings are also far
                  away on the curve. This parameterization for a space-filling
                  curve is motivated by parallel radix sort.
                  <br />
                  A disadvantage of the Z-order curve is that there are occasionally
                  large jumps between consecutive points, which results in discontinuous
                  work groups and thus excessively large bounding boxes with moderate 
                  probability.
                </li>
              </ul>
              <p>
                Below are demonstrations of our two approaches (this mode is 
                available with a keyboard toggle), where each color represents 
                a leaf node.
              </p>
              <div align="middle">
                <table style="width: 100%">
                  <tr align="center">
                    <td>
                      <img
                        src="static/gifs/high_bvh_whale.gif"
                        align="middle"
                        width="400px"
                        height="400px"
                      />
                      <figcaption>BVH Acceleration</figcaption>
                    </td>
                    <td>
                      <img
                        src="static/gifs/morton_whale.gif"
                        align="middle"
                        width="400px"
                        height="400px"
                      />
                      <figcaption>Z-Order Sort Acceleration</figcaption>
                    </td>
                  </tr>
                </table>
              </div>

              <br />
              <h4>Limitations</h4>
              <p>
                OpenCL uses a subset of a version of C from 1999 and does not
                support passing arguments by reference or recursion, which
                significantly limited our implementations of ray tracing, which
                is a recursive algorithm. Combined with the inability to pass
                pointers into a function and the low frame rate of our zero
                bounce results, we were unable to implement bounces or any more
                advanced ray tracing techniques.
              </p>
              <p>
                OpenCL also does not have a build in random function, so we had
                to use a #define macro and some bit tricks found online to make
                a custom pseudorandom number generator that could generate
                multiple random numbers in a thread in a row, and maintain
                randomness between kernel dispatches by saving the random seed
                to a buffer between frames.
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Application Development</h2>
            <div class="content has-text-justified">
              <p>
                We began with starter code that rendered fractals to a window,
                and switched between fractals using keyboard interactions.
                Accordingly, we needed to set up some functionalities to adapt
                our project to this environment, including:
              </p>
              <ul>
                <li>Camera movement, zoom through click, drag, and scroll.</li>
                <li>
                  Keyboard inputs to switch between different point clouds and 
                  pause the simulation.
                </li>
                <li>
                  Debug scripts to show each BVH leaf node's particles in a
                  different color.
                </li>
                <li>
                  Integrated ray marching and ray tracing kernels with keybind
                  to toggle.
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Experiments</h2>
            <div class="content has-text-justified">
              <p>
                All of our experiments use a pixel resolution of 800 x 600. All
                FPS and timing data are averages over 500 frames.
              </p>

              <h4>Ray algorithm</h4>
              <p>
                Our experiments use 4096 boids, 1 ray per pixel, and 1 light
                sample per pixel.
              </p>
              <p>
                We observe that simulation time is generally negligible compared
                to rendering time for higher quality renders, and that ray
                marching with smoothing is roughly 7 times slower than
                traditional ray tracing with light blocking.
              </p>
              <div align="center">
                <table>
                  <tr>
                    <th scope="col"></th>
                    <th scope="col">FPS</th>
                    <th scope="col">Ray casting time (ms)</th>
                    <th scope="col">Simulation time (ms)</th>
                  </tr>
                  <tr>
                    <th scope="row">Ray tracing (light blocking)</th>
                    <td>33.4</td>
                    <td>24.4</td>
                    <td>3.9</td>
                  </tr>
                  <tr>
                    <th scope="row">Ray marching</th>
                    <td>6.1</td>
                    <td>174.3</td>
                    <td>4.0</td>
                  </tr>
                  <tr>
                    <th scope="row">Ray tracing (no light blocking)</th>
                    <td>81.9</td>
                    <td>5.4</td>
                    <td>4.3</td>
                  </tr>
                </table>
              </div>

              <br />

              <h4>Work group size</h4>
              <p>
                Our experiments use 4096 boids, 1 ray per pixel, and 1 light
                sample per pixel.
              </p>
              <p>
                With a larger work group size, we can better take advantage of
                local memory speedups, however we have larger bounding boxes so
                we have a smaller chance to skip BVH leaves. After experimenting
                with work group size, we found that an 8x8 work group offered
                the best performance when combined with the BVH, giving us 64
                leaves with 64 spheres each. Compared to the 16x16 maximal work
                group size offered by the Apple M1 GPU, this was a roughly 25%
                speedup.
              </p>
              <div align="center">
                <table>
                  <tr>
                    <th scope="col"></th>
                    <th scope="col">FPS</th>
                    <th scope="col">Rendering time (ms)</th>
                  </tr>
                  <tr>
                    <th scope="row">16 x 16</th>
                    <td>37</td>
                    <td>20.2</td>
                  </tr>
                  <tr>
                    <th scope="row">8 x 8</th>
                    <td>44</td>
                    <td>15.6</td>
                  </tr>
                </table>
              </div>

              <br />

              <h4>Acceleration algorithm</h4>
              <p>
                Our experiments use ray tracing with light blocking, 4096 boids,
                1 ray per pixel, 4 light samples per pixel, and a 16x16 work group size.
              </p>
              <p>
                We implemented a basic BVH of depth 4 with binary splits along
                the longest axis of the bounding box. This gave us 16 leaves of
                size 256, which matches the size of each work group. We also
                attempted to sort the points along the Z-order curve, which is a
                space filling curve. In this way, points within each contiguous
                chunk of 256 should be close to each other.
              </p>
              <p>
                While the Z-order sort has a considerably lower construction time,
                it is about 50% slower than the basic BVH, likely due to the 
                discontinities causing unnecessarily large bounding boxes from our
                arbitrary chunking.
              </p>
              <p>This optimization gave us a 4x speedup with the BVH approach.</p>
              <div align="center">
                <table>
                  <tr>
                    <th scope="col"></th>
                    <th scope="col">FPS</th>
                    <th scope="col">Construction time (ms)</th>
                    <th scope="col">Rendering time (ms)</th>
                    <th scope="col">Simulation time (ms)</th>
                  </tr>
                  <tr>
                    <th scope="row">None</th>
                    <td>13.4</td>
                    <td>0</td>
                    <td>67.1</td>
                    <td>3.9</td>
                  </tr>
                  <tr>
                    <th scope="row">BVH</th>
                    <td>42.6</td>
                    <td>0.94</td>
                    <td>16.9</td>
                    <td>4.0</td>
                  </tr>
                  <tr>
                    <th scope="row">Z-order sort</th>
                    <td>33</td>
                    <td>0.35</td>
                    <td>24</td>
                    <td>4.0</td>
                  </tr>
                </table>
              </div>

              <br />

              <h4>GPU Memory Optimization</h4>
              <p>
                Our experiments use ray tracing without light blocking, 4096
                boids, 4 rays per pixel, and 4 light samples per pixel.
              </p>
              <p>
                Memory from the host program on the CPU must be uploaded to the
                global memory of the GPU, but each work group on the GPU has
                access to a shared local memory within the work group that is
                faster. We can take advantage of this by having each thread
                fetch data from global memory in parallel to local memory, and
                then running all required $O(n)$ operations on local memory
                instead. Between these fetches, we must also call barrier() to
                ensure thread synchronization within the work group.
              </p>

              <p>This optimization gave us about a 33% speedup.</p>

              <div align="center">
                <table>
                  <tr>
                    <th scope="col"></th>
                    <th scope="col">FPS</th>
                    <th scope="col">Rendering time (ms)</th>
                    <th scope="col">Simulation time (ms)</th>
                  </tr>
                  <tr>
                    <th scope="row">Global memory</th>
                    <td>34.3</td>
                    <td>22.2</td>
                    <td>4.0</td>
                  </tr>
                  <tr>
                    <th scope="row">Local memory</th>
                    <td>46</td>
                    <td>14.9</td>
                    <td>4.0</td>
                  </tr>
                </table>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">Gallery</h2>
            <div class="content has-text-justified"></div>
          </div>
        </div>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/basketball.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>
                Giant Basketball Dunking on Hoop of Pretzels
              </figcaption>
            </td>
            <td>
              <img
                src="static/gallery/camera.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Digital Camera on a Tripod</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/cupcake.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Cupcake Wearing Boxing Gloves</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/godzilla_battle.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Godzilla Battling Giant Soup Can</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/guitar.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Guitar</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/monster.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Loch Ness Monster Knitting a Sweater</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/octopus.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Octopus</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/panda.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Panda</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/roses.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Bouquet of Roses</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/shrek.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Shrek</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/whale.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Snail</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/telephone_booth.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>British Telephone Booth</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/coke.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Coke Bottle</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/deer.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Family of Deer</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/mario.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Mario</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/snail.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Snail</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/snail_bvh.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Snail BVH Visualization</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/snail_morton.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Snail Z-Order Sort Visualization</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div align="middle">
        <table style="width: 90%">
          <tr align="center">
            <td>
              <img
                src="static/gallery/snail_raymarch.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Snail Raymarching with Smoothing</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/guitar_raymarch.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Guitar Raymarching with Smoothing</figcaption>
            </td>
            <td>
              <img
                src="static/gallery/roses_shadow.png"
                align="middle"
                width="500px"
                height="500px"
              />
              <figcaption>Bouquet of Roses with Light Blocking</figcaption>
            </td>
          </tr>
        </table>
      </div>

      <div class="container is-max-desktop" style="margin-top: 2em">
        <div class="columns is-centered has-text-centered">
          <div class="column">
            <h2 class="title is-3">References</h2>
            <div class="content has-text-justified">
              <p>External resources were useful for the following:</p>
              <ul>
                <li>
                  <a
                    href="https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#the-raymarching-algorithm"
                    target="_blank"
                    >Ray Marching algorithm and smoothing</a
                  >
                </li>
                <li>
                  <a
                    href="https://iquilezles.org/articles/smin/"
                    target="_blank"
                    >Smooth minimum SDF</a
                  >
                </li>
                <li>
                  <a
                    href="https://developer.nvidia.com/blog/thinking-parallel-part-ii-tree-traversal-gpu/"
                    target="_blank"
                    >BVH on GPU</a
                  >
                </li>
                <li>
                  <a
                    href="https://developer.nvidia.com/blog/thinking-parallel-part-iii-tree-construction-gpu/"
                    target="_blank"
                    >Z-order curve</a
                  >
                </li>
                <li>
                  <a
                    href="https://cs184.eecs.berkeley.edu/sp24/lecture/9/ray-tracing-and-acceleration-str"
                    target="_blank"
                    >Ray intersection with axis aligned box</a
                  >
                </li>
                <li>
                  <a
                    href="https://github.com/9prady9/CLGLInterop"
                    target="_blank"
                    >OpenCL + OpenGL Interop</a
                  >
                </li>
                <li>Camera code from Homework 3</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <div class="container is-max-desktop" style="margin-top: 2em">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h2 class="title is-3">Member Contributions</h2>
          <div class="content has-text-justified">
            <h4>Ralph Cao</h4>
            <ul>
              <li>Unity demo for the flocking algorithm</li>
              <li>
                Reimplemented real time ray tracing in OpenCL from scratch based
                on homework 3, along with rewriting the camera math and camera
                movement code
              </li>
              <li>
                Implemented flocking algorithm in OpenCL using a compute shader
                for speedup
              </li>
              <li>
                Tested and implemented different GPU optimizations listed above
              </li>
              <li>Implemented BVH visualizations</li>
            </ul>
            <h4>Arjun Damerla</h4>
            <ul>
              <li>Implemented Ray Marching</li>
              <li>
                Implemented different smoothing algorithms for ray marching,
                ultimately settling on one of them
              </li>
            </ul>
            <h4>Preston Fu</h4>
            <ul>
              <li>
                Point cloud pipeline (LM prompting, 2D image generation, 3D
                point cloud generation, filtering, C++ numpy input)
              </li>
              <li>Parts of the camera and flocking kernels</li>
              <li>Timing utility functions for performance testing</li>
            </ul>
            <h4>Julia Sun</h4>
            <ul>
              <li>Assisted with first iteration of ray marching</li>
              <li>
                Created project propsal, milestone report, and finalized final
                project webpage
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <footer class="footer" style="margin-top: 3em">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content" align="middle">
              The website design is adapted from
              <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
